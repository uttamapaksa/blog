---
id: 5
title: "혼자 공부하는 컴퓨터 구조+운영체제 (저자: 강민철)"
datetime: "2024-12-01"
category: "Development"
thumbnail: "https://contents.kyobobook.co.kr/sih/fit-in/458x0/pdt/9791162243091.jpg"
source: "https://product.kyobobook.co.kr/detail/S000061584886"
summary: "컴퓨터 구조와 운영체제의 필수적인 내용들을 담고 있다. 컴퓨터의 부품과 역할, 명령어 처리 과정 등을 단계별로 설명하고 운영체제가 컴퓨터 부품을 어떻게 사용하는지 전체적인 과정을 알 수 있다."
---

## 1. 컴퓨터 구조 시작하기
### 1-1. 컴퓨터 구조를 알아야 하는 이유
컴퓨터 구조는 실력있는 개발자라면 반드시 알아야 할 기본 지식이다. 문법만 알고 있을 때보다 문제해결 잘 할 수 있다. 코드를 올바르게 작성했는데도 오류가 날 때 특히 그렇다. 작성만 할 줄 아는 것을 넘어 다양한 문제를 스스로 해결할 줄 아는 개발자가 필요하다. 성능/용량/비용의 문제는 프로그래밍 언어 문법으로 해결되는 게 아니다. 두려운 미지의 대상이었던 컴퓨터가 분석이 대상이 될 것이다.
### 1-2. 컴퓨터 구조의 큰 그림
1. 컴퓨터가 이해하는 정보
   1. 데이터(data): 컴퓨터가 이해하는 정보를 말한다. 0과 1만으로 표현된다.
   2. 명령어(instruction): 컴퓨터를 정의하자면 명령어를 처리하는 기계이다. 명령어는 컴퓨터를 작동시킨다.
2. 컴퓨터의 4가지 핵심 부품
   1. 중앙처리장치(CPU): 컴퓨터의 두뇌이다. 메모리의 값을 읽고, 해석하고, 실행한다. 내부에는 ALU(산술논리연산장치), 레지스터(바로 접근할 수 있는 작은 임시 저장 장치), 제어장치(제어 신호를 보내고 명령어를 해석하는 장치)가 들어있다.
   2. 주기억장치(main memory): 메모리는 현재 실행되는 프로그램의 명령어와 데이터를 저장한다. 프로그램이 실행되려면 반드시 메모리에 저장되어 있어야 한다. 주소값으로 저장되어 효율적으로 접근할 수 있다. RAM과 ROM이 있는데 메모리는 보통 RAM을 가리킨다.
   3. 보조기억장치(secondary storage): 메모리는 비싸고 용량이 적고 전원이 꺼지면 데이터가 날아가기 때문에 필요한 더 저렴하고 용량이 크고 전원이 꺼져도 저장되는 저장 장치이다. 보관할 프로그램을 저장한다. HDD, SSD, USB 등이 있다. 
   4. 입출력장치(I/O device): 컴퓨터 외부에 연결되어 컴퓨터 내부와 정보를 교환하는 장치이다. 마이크, 스피커, 프린터, 마우스, 키보드 등이 있다.
   5. 메인보드와 시스템 버스: 위에서 말한 4가지 핵심 부품들은 모두 메인보드에 연결된다. 이들은 메인보드 내부에 버스, 특히 시스템 버스(system bus)를 통해서 정보를 주고 받는다. 시스템 버스는 주소 버스, 데이터 버스, 제어 버스로 구성된다.

## 2. 데이터
### 2-1. 0과 1로 숫자를 표현하는 방법
컴퓨터가 0과 1로 표현된 정보만 이해하는데도 더 큰 수를 쓸 수 있는 것은 이진법을 사용하기 때문이다. 앞에 0b를 붙인다. 0과 1을 나타내는 가장 작은 정보 단위는 비트bit이고, 8개 묶으면 바이트byte, 1000개 묶으면 킬로바이트KB다. CPU가 한번에 처리하는 비트 개수 단위는 워드라고 하고 보통 CPU는 64비트 워드(x64)이다. 음수를 표현하려면 2의 보수를 사용한다. 어떤 수를 그보다 큰 2^n에서 뺀 값으로, 0과 1을 모두 반전시킨 후 1을 더한 값이다. 11의 보수는 16-1=5이다. 양수 5와 비교하기 위해 플래그를 사용한다. 자릿수를 많이 차지하면 앞에 0x를 붙이는 십육진법을 사용하기도 한다.
### 2-2. 0과 1로 문자를 표현하는 방법
컴퓨터가 0과 1로 표현된 정보만 이해하는데도 문자를 쓸 수 있는 것은 문자 집합character set을 인코딩하기 때문이다. 문자 집합은 컴퓨터가 인식할 수 있는 문자 모음이다. 인코딩하면 0과 1로 표현된다. 반대로 디코딩은 문자 코드를 사람의 문자로 변환하는 것이다. 아스키ASCII 문자는 초창기 문자 집합으로 128개의 문자를 표현할 수 있다. 아스키 문자에 대응되는 고유한 수를 아스키 코드라고 한다. 아스키 문자론 모든 글자를 표현하기 턱없이 부족하기 때문에 한글 인코딩을 위한 EUC-KR, 국제적 표현을 위한 유니코드 등의 문자 집합이 나왔다. 유니코드의 경우 부여된 값을 다시 인코딩(Unicode Transformation Format)하는 UTF-8, UTF-16 같은 방식이 있다.

## 3. 명령어
### 3-1. 소스 코드와 명령어
1. 고급 언어와 저급 언어: 컴퓨터는 명령어를 처리하는 기계이다. 컴퓨터는 0과 1의 명령어 비트로 이루어진 기계어만을 이해하고 실행한다. 고급 언어인 C, Java, Python과 명렁어 모음인 저급 언어 기계어와 어셈블리어는 기계어로 변환되어야만 실행된다.
2. 컴파일 언어와 인터프리터 언어: 소스코드 실행 시 저급 언어로 변환되는 방식에 따라 구분된다. 컴파일 언어는 소스코드 전체가 변환되어 실행되고 인터프리터 언어는 한 줄씩 실행된다. 인터프리터 언어는 오류 발생 전까지의 코드들은 실행된다. 한 언어가 꼭 하나의 방식으로만 수행되진 않는다.
3. 목적 파일 vs 실행 파일: 목적 코드로 이루어진 파일이 목적 파일이다. .exe와 같이 실행 코드로 이루어진 파일이 실행 파일이다. 링킹 작업을 거치면 목적 파일은 실행 파일이 된다.
### 3-2. 명령어의 구조
1. 명령어의 구성
   1. 연산 코드: 명령어가 수행할 연산. 연산자. 연산 코드 필드에 담긴다. 크게 데이터 전송, 산술/논리 연산, 제어 흐름 변경, 입출력 제어로 나눌 수 있다.
   2. 오퍼랜드: 연산에 사용할 데이터 혹은 데이터가 저장된 위치. 피연산자. 오퍼랜드(주소) 필드에 담긴다. 명령어 길이 때문에 대개 메모리 주소나 레지스터 이름을 담는다. 오퍼랜드가 1개면 1-주소 명령어라고 한다. 
2. 주소 지정 방식
   1. 즉시 주소 지정 방식: 사용할 데이터 직접 명시. 데이터 크기가 작지만 가장 빠르다.
   2. 직접 주소 지정 방식: 유효 주소 직접 명시
   3. 간접 주소 지정 방식: 유효 주소의 주소 명시. 메모리 접근을 두 번해서 느리다.
   4. 레지스터 주소 지정 방식: 레지스터 직접 명시. 메모리 접근보다 빠르지만 레지스터 개수나 크기에 따른 제한이 생긴다.
   5. 레지스터 간접 주소 지정 방식: 메모리의 주소를 저장한 레지스터 명시. 메모리 접근이 한 번으로 줄어든다.

## 4. CPU의 작동 원리
### 4-1. ALU와 제어장치
1. ALU: 레지스터를 통해 피연산자를 받아들이고, 제어장치로부터 수행할 연산을 알려주는 제어 신호를 받아들일 후, 이들로 연산을 수행한 뒤 결과값과 플래그를 내보낸다. 결과값은 우선 레지스터에 저장한다. 플래그는 플래그 레지스터에 부호나 오버플로우 등의 추가 정보를 담고 있다. 그 외에 가산기나 보수기, 시프터 등 여러 계산을 위한 회로들이 ALU 내부에 있다.
2. 제어장치: 제어 신호를 보내고 명령어를 해석하는 가장 정교한 부품이다. 제어장치가 받아들이는 대표적인 정보에는 컴퓨터 부품들의 시간 단위인 클럭clock 신호, 명령어 레지스터로부터 받은 해석해야 할 명령어, 제어 버스를 통해 받는 CPU 외부의 제어 신호 등이 있다. 제어장치가 내보내는 정보에는 제어 버스를 통헤 메모리나 입출력장치에 전달하는 CPU 외부 제어 신호와 ALU나 레지스터에 전달하는 CPU 내부 제어 신호가 있다. 
### 4-2. 레지스터
프로그램 실행 전후로 명령어와 데이터가 반드시 레지스터에 저장되기 때문에 레지스터만 잘 관리하면 실행 흐름을 파악할 수 있다.
1. 레지스터 종류
   1. 프로그램 카운터: 메모리에서 읽어 들일 명령어의 주소를 저장한다. 명령어 포인터라고 부르는 CPU도 있다.
   2. 명령어 레지스터: 방금 메모리에서 읽어 들인 명령어를 저장한다. 제어장치는 이 명령어 레지스터 속 명령어를 받아들이고 해석한다.
   3. 메모리 주소 레지스터: 메모리의 주소를 저장한다. CPU가 읽고자 하는 주소 값을 주소 버스로 보낼 때 이 레지스터를 거친다.
   4. 메모리 버퍼 레지스터: 메모리와 주고받을 값(데이터와 명령어)을 저장한다. 메모리에 쓰거나 읽을 값은 이 레지스터를 거친다. 주소 버스로 주고받을 값은 메모리 주소 레지스터, 데이터 버스로 주고받을 값은 메모리 버퍼 레지스터를 거치는 것이다. 
   5. 플래그 레지스터: ALU 연산 결과에 따른 플래그를 저장한다.
   6. 범용 레지스터: 다양하고 일반적인 상황에서 자유롭게 사용할 수 있다. 데이터와 주소를 모두 저장할 수 있다. 현대 대다수 CPU는 모두 범용 레지스터를 갖고 있다.
   7. 스택 포인터: 메모리의 스택 영역의 꼭대기를 가리킨다. 스택에 마지막으로 저장한 값의 위치를 저장한다.
   8. 베이스 레지스터
2. 추가적인 주소 지정 방식
   1. 스택 주소 지정 방식: 스택과 스택 포인터를 이용한 주소 지정 방식이다.
   2. 변위 주소 지정 방식: 오퍼랜드의 값(변위)과 특정 레지스터의 값을 더하여 유효 주소를 얻어내는 방식이다. 이때의 명령어는 연산 코드 필드, 레지스터 필드, 오퍼랜드 필드 이렇게 세 필드가 있다. 상대 주소 지정 방식은 오퍼랜드와 프로그램 카운터를 더하고 베이스 레지스터 주소 지정 방식은 오퍼랜드와 베이스 레지스터의 값(기준 주소)을 더한다. 
### 4-3. 명령어 사이클과 인터럽트
1. 명령어 사이클: 하나의 명령어를 처리하는 정형화된 흐름을 말한다. 프로그램 속 각각의 명령어들은 일정한 주기로 반복된다. 명령어 인출 사이클과 실행 사이클을 반복하며 실행한다. 메모리 접근이 더 필요할 경우 간접 사이클을 거쳐 실행 사이클로 간다.
2. 인터럽트: CPU가 수행 중인 작업에 방해를 받아 명령 사이클이 중단되는 것을 말한다.
   1. 동기 인터럽트(예외): CPU에 의해 발생하는 인터럽트로 프로그래밍상 오류 등으로 발생한다. 보통 예외exception라고 부른다.
      1. 폴트: 예외를 처리한 후 예외가 발생한 명령어부터 실행을 재개하는 예외이다.
      2. 트랩: 예외를 처리한 후 예외가 발생한 다음 명령어부터 실행을 재개한다. 주로 디버깅에 쓰인다.
      3. 중단: CPU가 실행중인 프로그램을 강제로 중단시킬 수밖에 없는 심각한 오류를 발견했을 때 발생한다.
      4. 소프트웨어 인터럽트: 시스템 호출이 발생했을 때 나타난다.
   2. 비동기 인터럽트(인터럽트): 주로 입출력장치에 의해 발생하는 하드웨어 인터럽트이다. 완료 알림 같은 역할을 한다. 작업을 끝낸 입출력장치가 인터럽트를 보낸다. 알림 전까지는 CPU가 다른 일을 계속 할 수 있다. 보통 인터럽트interrupt라고 부른다.
      1. 입출력장치가 CPU에 인터럽트 요청 신호를 보낸다.
      2. CPU는 실행 사이클이 끝나고 명령어를 인출하기 전 항상 인터럽트 여부를 확인한다.
      3. CPU는 인터럽트 요청을 확인하고 플래그 레지스터의 인터럽트 플래그를 통해 현재 인터럽트를 받을 수 있는지 확인한다.
      4. 인터럽트를 받아들일 수 있다면 CPU는 지금까지의 작업을 스택에 백업한다.
      5. CPU는 인터럽트 벡터를 참조하여 인터럽트 서비스 루틴(인터럽트 핸들러)을 실행한다. 인터럽트 서비스 루틴은 인터럽트 발생 시 해당 인터럽트를 어떻게 처리할지 알려주는 프로그램이다. 인터럽트 벡터는 어떤 서비스 루틴을 실행시킬지 구분하는 정보다.
      6. 인터럽트 서비스 루틴 실행이 끝나면 4에서 백업해 둔 작업을 복구하여 실행을 재개한다.

## 5. CPU 성능 향상 기법
### 5-1. 빠른 CPU를 위한 설계 기법
1. 클럭: 컴퓨터 부품들은 클럭 신호에 맞춰 움직이기 때문에 CPU 클럭이 높을수록 빨라진다. 1초에 몇 번 클럭이 반복되는지는 Hz단위로 측정한다. Inter Core i7은 클럭은 기본 2.5GHz이다.
2. 코어: 코어는 명령어를 실행하는 부품이다. 이것은 원래 CPU의 정의였다. 기술에 발달로 이젠 CPU 내부에 여러개의 CPU를 넣을 수 있는 셈이다. 코어를 여러개 포함하는 CPU가 멀티코어다. 무조건 많은 코어에 분배한다고 빨라지진 않는다.
3. 스레드: 스레드는 실행 흐름의 단위를 말한다. 하드웨어적 스레드는 하나의 코어가 동시에 처리하는 명령어 단위를 뜻한다. 하나의 코어가 여러 명령어를 동시에 처리하면 멀티스레드 프로세서(CPU)가 된다. 코어가 여러 명령어를 동시에 처리하려면 레지스터 세트를 여러개 가지고 있으면 된다. 소프트웨어적 스레드는 하나의 프로그램에서 독립적으로 실행되는 단위를 뜻한다. 주로 프로그래밍 언어나 운영체제에서 얘기하는 스레드다. 
### 5-2. 명령어 병렬 처리 기법
1. 명령어 파이프라인: 명령어 처리과정을 클럭 단위로 명령어 인출, 명령어 해석, 명령어 실행, 결과 저장 4단계 나눴을 때 단계가 겹치지 않는다면 각 단계별로 다른 명령어를 동시에 실행시켜 최대 4개를 실행시킬 수 있다. 명령어를 공장 생산 라인처럼 겹쳐 실행시키는 것이다. 높은 성능을 가져온다. 파이프라인 위험도 있다. 데이터 위험은 데이터 의존성, 제어 위험은 분기로 인한 프로그램 카운터의 갑작스러운 변화, 구조적 위험(자원 위험)은 다른 명령어들의 같은 CPU 부품 동시 사용에 의해 발생할 수 있다.
2. 슈퍼스칼라: 명령어 파이프라인을 여러 개 두는 것이다. 생산 라인이 늘어나는 셈이다. 가능한 CPU를 슈퍼스칼라 프로세서라고 부른다.
3. 비순차적 명령어 처리: 파이프라인이 멈추는 것을 방지하기 위해 데이터 의존성이 없는 명령어의 순서를 바꿔 처리하는 방법이다. OoOE라고도 한다. 명령어 파이프라인이나 슈퍼스칼라는 순차적 처리 방법이다.
### 5-3. CISC와 RISC
1. 명령어 집합: 파이프라이닝이 잘되려면 CPU가 처리하는 명령어가 파이프라이닝이 쉽도록 되어있어야 한다. CPU가 이해할 수 있는 명령어 집합 구조인 ISA가 CPU마다 다른데 이 ISA가 잘 설계되어야 한다. 명령어 병렬 처리에 유리한 ISA를 보기 위해 CISC와 RISC를 비교하면 좋다. 
2. CISC: 복잡한 명령어 집합을 활용하는 ISA이다. 강력한 기능의 명령어 집합과 가변 길이 명령어로 상대적으로 적은 수의 명령어로 프로그램을 실행할 수 있어 메모리를 절약한다는 장점이 있지만, 어차피 쓰이는 명령어만 쓰일 뿐더러 명령어들이 규격화되지 않고 수행 시간이 여러 클럭으로 가지각색이라 파이라이닝에 좋지 않다.
3. RISC: 간소화된 명령어 집합을 활용한다. CISC에 비해 명령어의 종류가 적고, 고정 길이 명령어에 짧고 규격화 되었으며, 되도록 1클럭 내외로 실행되도록 하여서 파이프라이닝에 최적화되어 있다. 메모리 접근도 load, store 두 개로 단순화했다. 대신 레지스터를 적극 활용한다. 

## 6. 메모리와 캐시 메모리
### 6-1. RAM의 특징과 종류
1. RAM의 특징: 전원이 끄면 날아가는 휘발성 저장장치이다. HDD, SSD, CD-ROM 등은 비휘발성 저장 장치이다. 보통 전자엔 실행할 대상, 후자엔 보관할 대상을 저장한다. 용량이 크면 기본적으로 보조기억장치를 접근할 일이 줄어들어 성능이 좋아진다.
2. RAM의 종류
   1. DRAM(Dynamic RAM): 시간이 지나면 동적으로 데이터가 사라지기 때문에 일정 주기로 데이터를 재활성화해야 한다. 그럼에도 집적도가 높아 대용량에 유리하고 소비 전력이 낮고 저렴하여 일반적으로 쓰인다.
   2. SRAM(Static RAM): DRAM보다 속도도 빠르고 데이터가 소실되지도 않지만, 집적도가 낮고 소비전력이 크며 가격이 비싸다. 대용량이 아니면서 속도가 빨라야 하는 캐시 메모리에 쓰인다.
   3. SDRAM(Synchronous Dynamic Ram): 클럭 신호와 동기화되어 클럭 타이밍에 맞춰 CPU와 정보를 주고 받을 수 있는 DRAM이다. 그냥 DRAM의 경우 CPU에 대기 시간이 생길 수 있다.
   4. DDR SDRAM(Double Data Rate SDRAM): SDRAM의 대역폭data rate을 두 배 넓힌 SDRAM이다. 대역폭은 데이터를 주고 받는 길의 너비이다. 한 클럭 당 두 번 데이터 전송이 가능해 SDR SDRAM보다 2배 빠르다. DDR4는 16배 빠르다. 
### 6-2. 메모리의 주소 공간
1. 물리 주소: 메모리 하드웨어가 저장되는 공간이다. 예들 들어 메모리 주소가 0~3000번지까지 있다면 실행 중인 프로그램 A는 500~1000번지, B는 1500~2000번지, C는 2500~3000번지에 올린다.
2. 논리 주소: CPU와 실행 중인 프로그램이 사용하는 주소이다. A, B, C 모두 각가 0~500번의 논리 주소를 가진다. 메모리 정보는 실시간으로 변하기 때문에 메모리 보호, 재배치, 이식성, 개발과 실행 환경과의 독립성 등을 위해 프로그램 자신의 고유한 연속된 논리 구조를 갖는 게 좋다. CPU와 주소 버스 사이에 위치한 메모리 관리 장치 MMU가 논리 주소에 베이스 레지스터 값을 더해서 물리 주소로 변환해준다.
3. 메모리 보호 기법: 다른 프로그램의 정보가 담긴 메모리 영역을 건드리지 않고 독립성을 보장할 수 있도록 offset값의 한계가 저장된 한계 레지스터의 값을 사용한다. 논리 주소가 한계 레지스터 값 이상이 되면 인터럽트(트랩)을 발생시킨다.
### 6-3. 캐시 메모리
1. 저장 장치 계층 구조: CPU에 얼마나 가까운가를 기준으로 계층적으로 나타낸다. 레지스터 > 캐시 메모리 > 메로리 > 보조기억장치 순이다. 저장 장치는 CPU와 가까울수록 빠르고 멀수록 느리다. 속도가 빠를수록 용량이 작고 비싸다.
2. 캐시 메모리: 레저스터보다 용량이 크고 메모리보다 빠른 SRAM 기반 저장 장치. 코어와 가까운 순으로 L1, L2, L3 캐시가 있는데 L3 캐시는 코어 외부에서 코어들이 공유한다.
3. 참조 지역성 원리: 사용자가 특정 프로그램을 쓰면 해당 프로그램이 모여있는 공간 근처를 집중적으로 접근하게 된다. 이렇게 접근한 메모리 공간 근처를 접근하려는 경향을 말한다. 캐시는 이 원리를 이용해 캐시 히트가 자주 되도록 CPU가 사용할 법한 대상을 예측하여 저장한다. 반면 메모리는 실행중인 대상, 보조기억장치는 보관할 대상을 저장한다.

## 7. 보조기억장치
### 7-1. 다양한 보조기억장치
1. 하드 디스크: 자기적인 방식을 이용해서 자기 디스크magnetic disk의 일종으로 지칭한다.
   1. 플래터platter: 데이터가 저장되는 원판.
   2. 스핀들spindle: 플래터를 돌리는 부품.
   3. 헤드head: 데이터를 읽고 쓰는 부품.
   4. 디스크 암disk arm: 헤드를 원하는 위치로 이동시키는 부품. 
   5. 트랙track: 플래터를 동심원으로 나눈 것.
   6. 섹터sector: 트랙을 피자 조각처럼 나눈 가장 작은 전송 단위.
   7. 실린더: 같은 위치의 트랙들이 모인 하나의 원통. 연속된 정보는 한 실린더에 기록된다. 한 실린더면 디스크 암을 움직이지 않아도 되기 때문이다.
   8. 탐색 시간, 회전 지연, 전송 시간: 탐색 시간은 헤드를 이동시키는 시간, 회전 지연은 헤드가 있는 곳으로 플래터를 회전시키는 시간, 전송 시간은 하드 디스크와 컴퓨터 간에 데이터를 전송하는 시간이다. 탐색 시간과 회전 지연을 단축시키기 위해서는 RPM을 높이는 것도 중요하지만 헤드를 조금만 움직여도 접근할 수 있도록 하는 것이 중요하다
2. 플래시 메모리: 전기적으로 데이터를 읽고 쓰는 반도체 기반 저장장치로 USB카드, SD카드, SSD 등이 있다. 크게 NAND회로 기반 NAND 플래시 메모리와 NOR 플래시 메모리로 나뒨다. 보통 NAND를 쓴다. 데이터를 저장하는 가장 작은 단위 셀cell에 몇 비트가 들어가는지를 기준으로 플래시 메모리 종류가 나뉜다. 1비트는 SLC, 2비트는 MLS, 3비트는 TLC(triple level cell) 타입이라고 한다. SLC는 입출력이 빠르고 수명도 길지만 비싸다. MLC는 반대다. 셀이 모이면 페이지, 페이지가 모이면 블록, 블록이 모이면 플레인, 플레인이 모이면 다이라고 한다. 읽기/쓰기는 페이지 단위, 삭제는 블록 단위로 이루어진다. 상태는 Free, Invalid, Valid 세 가지를 가진다. 하드 디스크와 달리 덮어쓰기가 불가능하다. 값을 변경한다면 새로 만들고, 유효한 값만 복사하여, 필요없는 값을 가진 Invalid 블록은 가비지 컬렉션이 삭제한다.
### 7-2. RAID의 정의와 종류
1. RAID의 정의  
대용량의 데이터를 안전하고 성능 좋게 이용하기 위해 여러 개의 물리적 보조기억장치를 하나의 논리적 보조기억장치처럼 사용하는 기술이다. RAID 레벨이라고 하는 다양한 구성 방법이 있다.
2. RAID의 종류
   1. RAID 0: 줄무늬처럼 단순하게 분산한다. 4개면 각각 A1, A2, A3, A4를 분산하는 식이다. 하나가 고장나면 다른 것도 못 써서 안전하지 않다.
   2. RAID 1: 원본과 균등한 복사본을 만들어서 쓴다. 그만큼 용량을 절반 손해본다.
   3. RAID 4: 완전한 복사본을 만드는 대신 오류를 검출하고 복구하기 위한 패리티 비트parity bit를 둔다. RAID에서 패리티 비트는 나머지 장치의 오류 검출과 복구를 해준다.
   4. RAID 5: RAID 4처럼 패리티 정보를 저장하는 디스크는 따로 두지 않고 분산하여 병목 현상을 해소한다.
   5. RAID 6: 서로 다른 2개의 패리티를 두는 방식이다. RAID 5보다 더 안전하지만 느리다. 

## 8. 입출력장치
### 8-1. 장치 컨트롤러와 장치 드라이버
1. 장치 컨트롤러
   1. 역할  
   입출력 장치는 CPU나 메모리에 비해 종류가 너무 많아 규격화하기 힘들고 데이터 전송률이 느려 병목이 생길 수 있다. 그래서 컴퓨터에 직접 연결하지 않고 입출력 제어기, 모듈이라고도 불리는 장치 컨트롤러라는 하드웨어를 사용해 시스템 버스와 입출력장치를 연결한다. CPU와 입출력장치 간의 통신을 번역가처럼 중개하고 오류를 검출하고 데이터 버퍼링을 해준다. 데이터를 버퍼buffer라는 임시 공간에 모았다가 한번에 보내거나 나눠서 보내는 데이터 버퍼링을 통해 전송률 차이를 낮춘다.
   2. 구성
      1. 데이터 레지스터: 주고받을 데이터가 담긴다.
      2. 상태 레지스터: 입출력 작업 준비가 되었는지, 완료 되었는지, 오류가 없는지 상태 정보를 저장한다.
      3. 제어 레지스터: 입출력장치가 수행할 내용에 대한 제어 정보와 명령을 저장한다.
2. 장치 드라이버: 장치 컨트롤러의 동작을 감지하고 제어함으로써 장치 컨트롤러가 컴퓨터 내부와 정보를 주고받을 수 있게 해주는 프로그램이다. 프로그램이니까 메모리에 저장된다. 장치 컨트롤러가 하드웨어적 통로라면 장치 드라이버는 소프트웨어적 통로다.
### 8-2. 다양한 입출력 방법
기본적으로 CPU의 시스템 버스를 이용하고, CPU의 이용을 방해하지 않기 위해 요즘은 입출력 버스라는 별도의 버스를 이용한다. 대부분 컴퓨터에 있다.
1. 프로그램 입출력(programmed I/O): 프로그램 속 명령어로 입출력장치를 제어하는 방법이다. 명령어 실행 중 입출력 명령어를 만나면 CPU는 입출력장치에 연결된 장치 컨트롤러를 통해, 제어 레지스터에 명령 내리고 상태 레지스터를 주기적으로 읽고 데이터 레지스터에 쓴다. 입출력을 수행한다. CPU가 여러 장치 컨트롤러 속의 레지스터 주소값을 모두 아는 법은 두 가지다. 메모리 주소와 같은 공간에 레지스터 주소를 저장하는 메모리 맵 입출력memory-mapped I/O와 주소 공간을 분리하는 고립형 입출력isolated I/O가 있다.
2. 인터럽트 기반 입출력(interrupt driven I/O): CPU가 장치 컨트롤러에게 명령하고, 입출력 작업이 끝나면 장치 컨트롤러가 인터럽트 요청을 해서, CPU가 인터럽트 서비스 루틴을 실행하는 방식이다. 여러 디바이스에서 요청이 오면 순차적으로 받고 인터럽트 비트를 비활성화 할 수도 있고, 인터럽트 비트를 활성화 해놓거나 인터럽트 비트를 무시하는 NMI가 발생한 경우 우선순위에 따라 처리할 수 있다. 보통 PIC(Programmable Interrupt Controller)라는 하드웨어가 우선순위를 처리한다. 단, PIC는 NMI까지 판별하진 못한다. 입출력 데이터를 메모리에 저장한다면 장치 컨트롤러 -> CPU -> 메모리 순으로, 내보낸다면 역순으로 데이터가 이동한다.
3. DMA 입출력(Direct Memory Access): CPU 부하 때문에 CPU를 거치지 않고 메모리와 입출력 장치 간에 주고받는 방식이다. 하드디스크 백업 작업이라면 CPU -> DMA 컨트롤러 -> 메모리 -> DMA 컨트롤러 -> 장치 컨트롤러 -> DMA 컨트롤러 -> CPU 인터럽트 요청 순으로 진행된다. CPU와 DMA 모두 시스템 버스를 쓰는데 동시 사용이 안되기 때문에 DMA는 CPU에게 버스를 이용하지 않도록 잠깐 허락을 구하고 집중적으로 이용하는 사이클 스틸링을 하기도 한다.

## 9. 운영체제 시작하기
### 9-1. 운영체제를 알아야 하는 이유
1. 운영체제: 모든 프로그램은 하드웨어 같이 실행에 필요한 요소들이 있는데 이를 시스템 자원이라고 한다. 앞서 본 부품들은 모두 자원이다. 프로그램에 필요한 자원을 할당하고 올바르게 실행되도록 돕는 특별한 프로그램을 운영체제operating system이라고 한다. 특별한 프로그램이기 때문에 메모리 내 커널 영역kernel space에 따로 적재된다. 사용자가 응용프로그램을 사용하는 나머지 영역은 사용자 영역user space라고 한다. 일반적으로 메모리에는 여러 개의 응용프로그램이 적재되는데 이들이 안 겹치게 적재되도록 하거나 CPU을 공정하게 점유할 수 있게 하거나 다른 프로그램을 대기시키는 등의 이을 한다. 사용자를 위한 프로그램들을 위한 프로그램이다.
2. 운영체제를 알아야 하는 이유: 운영체제를 이해하면 운영체제와 대화하며 하드웨어 상태를 알고 문제를 해결할 수 있기 때문이다. 프로그램과 하드웨어에 더 잘 이해할 수 있다. 운영체제는 개발자가 하드웨어 조작하는 코드를 직접 작성할 수 없게 편의를 제공해준다. 그렇기 때문에 프로그램과 하드웨어의 상태를 잘 알고 있다.
### 9-2. 운영체제의 큰 그림
1. 커널: 운영체제의 핵심 서비스, 자원에 접근하고 조작하는 기능을 담당하는 부분이다. 운영체제는 현존하는 프로그램 중 가장 규모가 큰 프로그램 중 하나다. 리눅스는 소스코드가 천만줄이 넘는다. 많은 기능들 중 핵심 서비스를 커널이 담당한다. 보통 운영체제에 대해 말한다면 커널을 말하는 것이다. GUI, CLI 같은 UI는 운영체제가 서비스하지만 커널이 담당하지는 않는다. 
2. 이중 모드: CPU가 명령어를 실행하는 모드를 크게 사용자 모드, 커널 모드로 구분하는 방식이다. 사용자 모드는 운영체제 서비스를 제공받을 수 없는 실행 모드다. 하드웨어 자원에 접근하는 명령어를 실행할 수 없다. 커널 모드는 운영체제 서비스, 즉 커널 영역의 코드 실행을 할 수 있는 모드이다. 자원에 접근할 수 있다. 자원은 운영체제가 본인만 접근할 수 있도록 보호되기 때문이다. 이 때 운영체제 서비스를 제공받기 위해 하는 요청을 시스템 호출system call이라고 한다. 시스템 콜은 소프트웨어 인터럽트이다. 시스템 콜이 끝나면 사용자 모드로 복귀하여 실행을 계속 해나간다.
3. 운영체제의 핵심 서비스
   1. 프로세스 관리: 프로세스는 실행중인 프로그램이다. 하나의 CPU는 한 번에 하나의 프로세스만 실행할 수 있기 때문에 운영체제는 다양한 상황에서 프로세스들을 번갈아가면서 일목요연하게 실행해야 한다. 
   2. 자원 및 접근 할당: 프로세스들에게 CPU를 어떻게 공정하고 효율적으로 분배할 것인지, 메모리에는 프로세스들을 어떻게 할당할 것인지, 입출력 장치의 인터럽트는 어떻게 처리할 것인지 등을 관리하는 CPU 스케줄링을 한다.
   3. 파일 시스템 관리: 파일 시스템에서 컴퓨터의 여러 파일들을 디렉토리로 관리한다.
4. 가상 머신과 시스템 호출의 발전
   1. 가상 머신  
   소프트웨어적으로 만들어낸 가상 컴퓨터이다. 가상 머신을 설치하면 새로운 운영체제와 운영 프로그램을 설치하고 실행할 수 있다. 가상 머신 또한 응용 프로그램이기 때문에 가상머신, 그 안의 운영체제와 응용프로그램 모두 사용자 모드로 작동한다. 그렇다면 가상 머신의 운영체제 서비스(커널에의 접근)를 받기 어렵다. 그래서 가상화를 지원하는 CPU는 가상 머신을 위한 모드 하이퍼 바이저 모드를 따로 두어서, 가상 머신의 응용프로그램은 하이퍼바이저 모드로 가상 머신의 운영체제로부터 운영체제 서비스를 받을 수 있다.
   2. 시스템 호출의 종류
      1. 프로세스 관리: fork(), execve(), exit(), waitpid()
      2. 파일 관리: open(), close, read(), write(), stat()
      3. 디렉터리 관리: chdir(), mkdir(), rmdir() 
      4. 파일 시스템 관리: mount(), unmount()

## 10. 프로세스와 스레드
### 10-1. 프로세스 개요
1. 프로세스 직접 확인하기
   프로그램들은 보조기억장치에 데이터 덩어리로 있다가 실행되면 메모리에 올라간다. 메모리에 올라간 프로그램들이 프로세스다. 작업관리자의 프로세스 탭이나 ps 명령어로 확인할 수 있다. 사용자가 보는 앞에서 실행되는 프로세스는 포그라운드 프로세스, 뒷편에서 실행되는 프로세스는 백그라운드 프로세스라고 한다. 사용자와 상호작용하지 않고 묵묵히 정해진 일만 수행하는 프로세스는 유닉에서는 데몬, 윈도우에서는 서비스라고 한다.
2. 프로세스 제어 블록(PCD, process control block): PCB는 프로세스와 관련된 정보를 저장하는 자료구조이다. 커널 영역에 생성된다. PCB를 통해 빠르게 번갈아가는 프로세스들에 자원을 배분한다. 새로운 프로세스가 생기면 PCB가 생기고 종료하면 해당 PCB가 폐기된다.
   1. 프로세스 ID: 특정 프로세스를 식별하기 위해 부여하는 고유한 번호. 같은 프로그램을 2번 실행해도 PID는 2개 생긴다.
   2. 레지스터 값: 자신의 차례가 돌아오면 이전까지 사용했던 레지스터의 중간값들을 모두 복원헤야 하기 때문에 프로그램 카운터를 비롯한 값들을 저장한다.
   3. 프로세스 상태: 현재 어떤 상태인지도 기록되어야 한다. 입출력 대기중인지, CPU 대기중인지, CPU 이용중인지 등의 정보가 저장된다.
   4. CPU 스케줄링 정보: 언제 어떤 순서로 CPU를 할당받을지에 대한 정보.
   5. 메모리 관리 정보: 프로세스마다 어느 메모리 주소에 저장되어 있는지 정보 
   6. 사용한 파일과 입출력장치 목록: 어떤 파일을 열었는지, 어떤 입출력 장치가 할당되었는지 정보
3. 문맥 교환(conext switch): 기존 프로세스의 문맥을 PCB에 백업하고, 새로운 프로세스의 PCB로부터 문맥을 복구하여 실행하는 것
4. 프로세스의 메모리 영역(사용자 영역)
   1. 코드 영역: 데이터가 아닌 명령어 기계어가 담겨 있다. CPU가 실행할 명령어기 때문에 read-only 공간이다.
   2. 데이터 영역: 프로그램이 실행되는 동안 유지될 데이터가 저장된다. 전역 변수가 대표적이다. 코드 영역과 데이터 영역은 크기가 변하지 않는 정적 할당 영역이다.
   3. 힙 영역: 프로그래머가 직접 할당할 수 있는 저장 공간이다. 메모리 누수를 막기 위해선 언젠가는 사용 공간을 반환해야 한다.
   4. 스택 영역: 데이터를 일시적으로 저장하는 공긴이다. 잠깐 쓰다가 말 매개 변수, 지역 변수가 저장된다. 스택과 힙 영역은 크기가 변할 수 있기 때문에 동적 할당 영역이다.
### 10-2. 프로세스 상태와 계층 구조
1. 프로세스 상태
   1. 생성 상태(new): 이제 막 메모리에 적재되어 PCB를 할당받은 상태
   2. 준비 상태(ready): 당장이라도 CPU를 할당받아 실행할 수 있는 상태
   3. 실행 상태(running): 차례가 되어 CPU를 할당받아 실행중인 상태. 할당된 시간을 모두 사용한다면 타이머 인터럽트가 발생해 준비 상태로 돌아가고, 입출력장치를 사용한다면 입출력 작업이 끝날 때까지 대기 상태가 된다.
   4. 대기 상태(blocked): 입출력 작업은 CPU에 비해 처리 속도가 느리기 때문에 기다리는 상태. 입출력 작업이 끝나면 준비 상태로 돌아간다.
   5. 종료 상태(terminated): 프로세스가 종료된 상태. 프로세스와 관련된 PCB와 메모리를 정리한다.
2. 프로세스 계층 구조: 프로세스는 실행 도중 시스템 호출로 다른 프로세스를 생성할 수 있다. 이렇게 생긴 프로세스를 부모 프로세스와 자식 프로세스라고 한다. 각각 다른 PID를 가진다. 많은 운영체제에서 프로세스들은 계층적으로 생겨나고 관리된다. 예를 들어 bash를 키고 Vim 실행시키고자 한다면 최초 프로세스, 로그인 프로세스, bash 프로세스 3개의 부모 계층이 생긴다.
   1. 최초 프로세스(init, systemmd, launchd)
   2. 로그인 프로세스
   3. bash 프로세스
   4. Vim 프로세스
3. 프로세스 생성 기법
   1. 부모가 fork를 통해 자신의 복사본을 자식 프로세스에 생성한다. 당연히 fork하면 PID나 메모리 위치는 달라지고,자식의 PPID엔 부모의 PID가 저장된다. (bash에 ls 명령어를 친다면 bash는 자식을 fork한다)
   2. 만들어진 복사본인 자식 프로세스는 exec를 통해서 자신의 메모리 공간을 자신의 것으로 교체한다. 아무도 exec를 호출하지 않는다면 부모와 자식은 같은 코드를 병행하여 실행한다. (자식 프로세스는 exec를 통해 ls를 실행하는 프로세스로 바뀌고 메모리에도 ls 명령어 실행을 위한 내용들이 채워진다)
### 10-3. 스레드
1. 스레드: 프로세스를 구성하는 실행의 흐름 단위를 말한다. 원래는 기본이 단일 스레드 프로세스였지만, 스레드라는 개념이 도입되고 멀티 스레드 프로세스가 되면서 하나의 프로세스가 여러 기능을 동시에 처리할 수 있게 되었다. 스레드는 각각 스레드 ID, 프로크램 카운터 값을 비롯한 레지스터 값, 스택으로 구성된다. 스택 영역들은 프로세스의 스택 영역에 저장된다. 이런 최소한의 정보만을 가지고 각각 돌아가고 프로세스의 자원인 힙 영역, 데이터 영역, 코드 영역은 공유하는 것이 스레드의 핵심이다. 최근의 OS들은 CPU에 스레드 단위로 작업을 전달한다. 리눅스는 이 둘을 구분하지 않고 태스크로 통칭한다. 리누스 토르발리는 실행의 문맥일 뿐 구분할 필요 없다고 보았다.
2. 멀티프로세스: 여러 프로세스를 동시에 실행하는 것. 프로세스 간에도 IPC, 공유 메모리, 소켓, 파이프 등을 통해 자원을 공유할 수 있다.
3. 멀티스레드: 여러 스레드를 동시에 실행하는 것. 자원을 아낄 수 있지만 공유 영역에 문제가 생기면 여러 스레드에 같이 문제가 생긴다. 

## 11. CPU 스케줄링
### 11-1. CPU 스케줄링 개요
1. 프로세스 우선순위: 프로세스마다 필요한 자원이 다르지만 필수적으로 필요한 것은 CPU이다. 운영체제는 CPU 스케줄링을 통해 CPU 자원을 효율적으로 배분해야 한다. CPU를 이용하는 CPU 버스트가 많은 프로세스는 CPU 집중 프로세스, 입출력장치를 이용하는 입출력 버스트가 많은 프로세스는 입출력 집중 프로세스라고 한다. 입출력 집중 프로세스를 빨리 실행시키고 입출력장치를 끊임없이 작동시켜서 일을 맡기는 게 좋다. 또 중요도가 높은 것을 먼저 실행시키는 게 좋다. 이 외의 우선순위 높은 프로세스는 ps -el 명령어를 통해 확인할 수 있다. 운영체제는 프로세스마다 우선순위를 부여하고 PCB에 명시한다.
2. 스케줄링 큐: CPU, 메모리, 입출력장치 별로 적재되고 싶은 프로세스들(PCB)을 스케줄링 큐를 통해 줄을 세워서 관리한다. 일일이 매번 모든 PCB를 조회하며 우선순위를 찾는 것은 비효율적이고 하드디스크, 메모리에 대한 우선순위를 원하는 프로세스도 다 다르기 때문이다. 대표적인 큐는 두 가지다.
   1. 준비 큐ready queue: CPU 할당을 기다리는 프로세스들이 서는 줄이다. 준비 상태에 대응된다. 준비 큐에 있는 PCB는 순서대로 실행되는데 우선순위가 높은 프로세스는 먼저 실행된다.
   2. 대기 큐waiting queue: 입출력장치를 기다리는 프로세스들이 서는 줄이다. 대기 상태에 대응된다. 무조건 순차적이 아니라 입출력이 완료되어 입출력 완료 인터럽트가 발생하면 운영체제는 대기 큐에서 작업이 완료된 PCB를 찾아서 준비큐로 이동시킨다.
3. 선점형 스케줄링과 비선점형 스케줄링: 선점형 스케줄링은 급할 경우 다른 프로세스가 CPU를 점유중인 것을 강제로 빼앗아 할당해주는 방식을 말한다. 한 프로세스가 자원을 독점할 수 없게 한 프로세스가 자원을 독점할 수 없게 한다. 타이머 인터럽도 이의 일종이다. 비선점은 무조건 한 기다려야 한다. 대부분의 운영체제의 방식은 전자이다. 
### 11-2. CPU 스케줄링 알고리즘
1. FCFS(First Come First Served) Scheduling: 선입 선처리 스케줄링으로 큐에 삽입된 순서대로 처리하는 비선졈형 스케줄링이다. 호위 효과가 생긴다는 단점이 있다.
2. SJF(Shortest Job First) Scheduling: 최단 작업 우선 스케줄링으로 시간이 짧은 프로세스 먼저 실행한다. 비선점형으로 분류되지만 선점형으로 만들 수도 있다.
3. RR(Round Robin) Scheduling: FCFS에 타임 슬라이스가 합쳐진 것으로 삽입된 순서대로 하되 정해진 시간만큼만 CPU를 점유한다. 타임 슬라이스 크기를 효율성을 고려해 잘 짜야한다. 시간에 끝나면 뺏기기 때문에 선점형이다.
4. SRT(Shrotest Remaining Time) Scheduling: 최소 잔여 시간 우선 스케줄링으로 SJF와 RR을 합친 방식이다. 작업 시간이 짧은 프로세스부터 처리하되 타임 슬라이스만큼 돌아간다. 선점형이다.
5. Priority Scheduling: 우선순위 스케줄링으로 높은 우선순위 프로세스부터 실행한다. 낮은 우선순위 프로세스는 끊임없이 연기되는 기아starvation가 발생할 수 있다. 이를 방지하기 위해 에이징aging 기법을 사용해 오래 대기할수록 우선순위를 높여준다.
6. Multilevel Queue Scheduling: 다단계 큐 스케줄링으로 우선순위별로 준비 큐를 여러개 사용하는 방식이다. 우선순위가 높은 큐의 프로세스를 먼저 다 실행하고 비면 그 다음 우선순위의 큐를 비운다. 유형별로 구분해 실행하기 편리하고 큐마다 다른 알고리즘을 사용할 수 있다.
7. Multilevel Feedback Queue Scheduling: 다단계 피드백 큐 스케줄링은 다단계 큐에서 프로세스들이 큐 사이를 이동할 수 있다. 일정 시간 동안 실행이 끝나지 않으면 우선순위를 낮춰서 CPU를 오래 쓰는 프로세스의 우선순위를 낮춘다. 반대로 낮은 우선순위 프로세스는 에이징을 써 높여준다.

## 12. 프로세스 동기화
### 12-1. 동기화란
1. 동기화의 의미: 프로세스 동기화는 프로세스들 사이에 수행 시기를 맞추는 것이다. 워드 프로세서에 입력할 때 입력 프로세스, 맞춤법 검사 프로세스, 화면 출력 프로세스와 같은 여러 프로세스들이 공동의 목표를 위해 협력하는데 이들이 시간을 맞춰서 실행되어야 한다.
   1. 실행 순서 제어를 위한 동기화: 순서대로 실행되어야 한다.
   2. 상호 배제를 위한 동기화: 한 자원에 대해 실행이 끝나고 접근하도록 동시 접근을 막아야 한다. 
2. 생산자와 소비자 문제: 계좌 잔액 문제처럼 소비자와 생산자가 동시에 총합에 접근해서 빼고 더하면, 값을 저장하기 전에 문맥 교환이 일어나는 등의 작동으로 예상치못한 값이 나올 수 있다. 10에서 생산자와 소비자가 각각 1씩 더하고 빼는데 생산자가 11을 구하고 값을 저장하기 전에 소비자에게 문맥 교환이 돼서 9를 만들고 저장해버리고 다시 생산자에게 돌아와서 11을 저장하여 최종값이 11이 될 수 있다. 
3. 공유 자원과 임계 구역: 공유 자원은 전역 변수, 파일, 입출력 장치 등 다양한데 이 중 동시에 실행하면 문제가 생기는 자원에 접근하는 코드 영역을 임계구역이라고 한다. 동시다발적으로 임계 구역의 코드를 실행하여 문제가 생기는 것을 레이스 컨디션race condition이라고 한다. 상호배제를 위한 동기화를 위해선 상호 배제(있으면 들어갈 수 없음), 진행(없으면 들어갈 수 있음), 유한 대기(있다고 무한정 대기해서는 안됨)라는 세 가지 원칙이 지켜져야만 한다.
### 12-2. 동기화 기법
1. 뮤텍스 락(MUTual Exclusion lock): 임계구역을 잠그는 자물쇠 기능을 하는 코드이다. 탈의실의 사용중 표시와 같다. 쉴새없이 잠금을 확인하는 busy lock이다. 임계구역 앞 뒤로 acquire(), release()를 놓으면 된다.
   1. lock: 자물쇠 역할을 하는 프로세스들이 공유하는 전역 변수
   2. acquire 함수: 임계 구역을 잠그는 역할
   3. release 함수: 잠금을 해제하는 역할
2. 세마포(semaphore): 여러 개의 공유 자원에 대한 도구이다. busy wait 문제를 해결하기 위해 남는 자리가 없다면 대기 상태로 만들고(sleep) 세마포를 위한 대기 큐에 넣는다. 작업이 끝나면 signal 함수에서 대기 중인 프로세스를 대기 큐에서 제거하여 준비 상태로 변경(wake up)한 후에 준비 큐에 넣는다. 상호 배제를 위한 도구지만 S=0으로 놓고 먼저 실행할 함수 앞에 signal, 뒤에 wait를 넣으면 순서대로 실행시킬 수도 있다.
   1. S: 임계 구역에 진입할 수 있는 프로세스의 개수(사용 가능한 공유 자원의 개수)를 나타내는 전역 변수
   2. wait 함수: 임계 구역에 들어가도 좋은지, 기다려야 할지를 알려주는 역할. 작업 대기 및 입장
   3. signal 함수: 임계 구역 앞에서 기다리는 프로세스에 '이제 가도 좋다'고 신호를 주는 역할. 작업 종료
3. 모니터(monitor): 세마포어에 비해 좀 더 편리하게 쓸 수 있게 나온 것이다. 세마포처럼 일일이 임계구역 앞뒤로 signal(), wait() 코드를 삽입해 놓는 것은 번거롭고 오류의 위험도 있기 때문이다. 모니터는 공유 자원에 접근하기 위한 인터페이스(통로)를 묶어 관리한다. 상호 배제를 위한 큐에 프로세스를 집어넣고 순서대로 공유 자원을 이용하도록 한다. 이 외에 조건 변수를 통해 실행 순서도 제어할 수 있다. 조건 변수로 wait, signal을 수행할 수 있는데, 예를 들어 조건 변수 x에 대해 x.wait()을 하면 x에 대한 대기 큐에 집어넣고, 다른 프로세스의 x.singal()에 의해 모니터 안으로 들어올 수 있다.

## 13. 교착 상태
### 13-1. 교착 상태란
1. 식사하는 철학자 문제: 왼쪽 포크와 오른쪽 포크 모두를 집어야 식사할 수 있는 철학자들이 원탁에 모여 있다. 이들이 동시에 왼쪽 포크를 들면 누구도 오른쪽 포크를 들 수 없어 식사를 할 수 없다. 이렇게 진행이 멈춰버리는 현상을 교착 상태dead lock이라고 한다. 해결하기 위해선 현재의 교착 상태를 정확히 표현(자원 할당 그래프)해야 하고 교착 상태의 근본적인 이유(교착 상태 발생 조건)을 알아야 한다.
2. 자원 할당 그래프: 프로세스는 원으로, 자원 종류는 사각형으로, 사용할 수 있는 자원의 개수는 사각형 내 점으로, 프로세스가 사용중이라면 자원에서 프로세스로 화살표, 프로세스가 기다리고 있다면 프로세스에서 자원으로 화살표를 하는 식으로 자원의 할당 상태를 나타낸 그래프다. 그래프가 원의 형태를 띄고 있을 때 데드락이 발생할 수 있다.
3. 교착 상태 발생 조건
   1. 상호 배제: 한 프로세스가 사용하는 자원을 다른 프로세스가 사용할 수 없다.
   2. 점유와 대기: 자원을 할당받은 상태에서 다른 자원을 할당받기 기다리는 상태다.
   3. 비선점: 강제로 다른 프로세스의 자원을 뺏을 수 없다.
   4. 원형(순환) 대기: 자원 할당 그래프가 원의 형태를 띄고 있다.
### 13-2. 교착 상태 해결 방법
1. 교착 상태 예방: 애초에 교착 상태 조건에 부합하지 않게 자원을 배분다는 것이다. 공유 자원으로 만들어서 상호 배제를 없애거나, 한 프로세스에게 자원을 몰아줘서 점유와 대기를 없애거나, 모든 자원을 뺏을 수 있게 해서 비선점을 없애거나, 모든 자원에 번호를 붙여 오름차순으로만 할당받게 해서 원형 대기를 없앨 수 있다. 그러나 예방 방법들은 기본적으로 어렵고 부작용이 커 활용성이 떨어진다.
2. 교착 상태 회피: 무분별한 자원 할당을 막고 데드락이 발생하지 않을 정도로만 조심해서 할당하는 방식이다. 교착 상태 없이 안전하게 자원을 할당할 수 있는 순서를 안전 순서열safe sequence이라고 한다. 안전 순서열이 존재하면 안전 상태, 아니라면 불안전 상태이다. A 먼저 끝내고 남은 자원 붙여서 B 끝내고 그 다음 자원 붙여서 C 끝내면 다 끝나는 상태다. 반대로 B, C가 이미 자원을 꽤 가지고 있어서 A를 끝내도 남은 걸로 B, C 어느 것도 못 끝댄다면 불안전 상태이다. 그러므로 안전 상태에서 안전 상태로 움직이는 방식으로만 자원을 할당하면 된다. 
3. 교착 상태 검출 후 회복: 사후 조치하는 방식이다. 주기적으로 교착 상태를 검사하고 검출되면 회복한다. 선점을 통해서 한 프로세스에 몰아거나, 강제 종료로 회복하는 단순하면서 확실한 방법이 있다. 강제 종료는 한번에 다 할 수 있고 하나씩 종료하면서 데드락 여부를 검사할 수 있다. 타조ostrich 알고리즘이라고 드물게 발생한다면 그냥 무시하는 방법도 있다.

## 14. 가상 메모리
### 14-1. 연속 메모리 할당
1. 스와핑(swapping): 메모리에 적재된 프로세스 중 현재 실행되지 않은 것들을 임시로 보조기억장치로 쫓아내고 그 빈 공간에 다른 실행할 프로세스를 적재하는 메모리 관리 기법이다. 쫓겨나는 보조기억장치의 영역을 스왑 영역swap scope라고 한다. 스왑 영역으로 옮겨지는 것은 스왑 아웃swap-out이라고 한다. 다시 메모리로 옮겨오는 것은 스왑 인swap-in이다. 스왑 인 시에는 기존과 다른 물리 주소에 적재될 수 있다. 그렇게 해서 실제 메모리보다 더 많은 프로세스를 적재할 수 있다.
2. 메모리 할당 방식 (연속적)
   1. 최초 적합(first fit): 최초로 발견한 적대 가능한 빈 공간에 프로세스를 배치하는 방식이다. 검색을 최소화하고 빠른 할당이 가능하다.
   2. 최적 적합(best fit): 프로세스가 적재될 수 있는 가장 작은 공간에 프로세스를 배치하는 방식이다. 빈 공간을 모두 검색해야 한다.
   3. 최악 적합(worst fit): 프로세스가 적재될 수 있는 가장 큰 공간에 프로세스를 배치하는 방식이다.
3. 외부 단편화(external fragmentation): 프로세스를 할당하기 어려울 만큼 작은 메모리 공간들로 인해 메모리가 낭비되는 현상이다. 연속적인 메모리 할당의 경우 프로세스 종료 후에 메모리가 군데군데 비어서 전체적인 빈 공간은 많아도 그 공간들을 효율적으로 쓸 수 없게 된다. 흩어져 있는 빈 공간들을 모으는 방법으로 압축이 있지만 그 동안 시스템이 멈추고 재배치하는 것이 비효율적이다.
### 14-2. 페이징을 통한 가상 메모리 관리
1. 가상 메모리: 연속 할당 방식은 외부 단편화 문제와 물리 메모리보다 큰 프로세스를 실행할 수 없는 문제가 있다. 가상 메모리는 실행하고자 하는 프로그램을 일부만 메모리에 적재하여 실제 물리 메모리보다 더 큰 프로세스를 실행할 수 있게 해준다. 페이징과 세그멘테이션 기법이 있다. 
2. 페이징: 메모리의 물리 주소 공간을 프레임 단위로 자르고, 프로세스의 논리 주소 공간을 페이지 단위로 자른 뒤 각 페이지를 프레임에 할당하는 가상메모리 기법이다. 현대 운영체제의 효율적인 메모리 관리 기법이다. 스와핑 역시 페이지 단위로 이루어져 페이지 아웃, 페이지 인 된다. 실행에 필요한 페이지만을 남기고 보조 기억 장치로 옮기면 물리 메모리 크기보다 더 큰 프로세스를 실행할 수 있다. 멀티프로세스에서 자식 프로세스가 쓰기 전까지는 부모 프로세스와 프레임을 공유하고 둘 중 하나가 쓰면 복사하는 쓰기 시 복사copy on right를 할 수 있는 이점도 있다. 단점은 내부 단편화라고 해서 페이지보다 작은 부분을 쓴다면 페이지 내에 빈 공간이 생기는 문제가 있을 수 있다. 
3. 페이지 테이블: 페이지를 연속적으로 실행하려면 프레임 위치도 순서대로 알아야 한다. 이를 위해 페이지 번호와 프레임 번호가 매핑된 페이지 테이블을 사용한다. 프로세스 별로 페이지 테이블을 메모리에 가지고 있다. 페이지 테이블 주소는 PCB에 기록되어 있다가 문맥 교환 시 CPU 내의 페이지 테이블 베이스 레지스터(PTBR)가 적어서 프로세스의 페이지 테이블 주소를 가리키게 한다. 그런데 페이지 테이블 접근, 프레임 접근 이렇게 두 번의 메모리 접근마저 줄이기 위해서 CPU는 (일반적으로 MMU 내에) TLB(Translation Lookaside Buffer)라는 캐시 메모리를 두어서 페이지 번호와 프레임 번호를 매핑해놔서 TLB 히트를 하면 더 빨리 프레임 주소를 알 수 있게 한다. 페이지 테이블이 모두 메모리에 있는 게 부담이라면 계층적으로 구성해서 하위 테이블들은 보조기억장치에 보관할 수도 있다. 메모리 참조 횟수가 늘기 때문에 다다익선은 아니다.
4. 페이징에서의 주소 변환: 특정 주소에 접근하기 위해선 페이지 번호page number와 변위offset를 알아야 한다. CPU가 5번 페이지, 변위 2라는 논리 주소에 접근하고 싶다면, 페이지 테이블에서 페이지 5번에 맞는 프레임 1번을 찾은 다음, 1번 프레임이 8번지에 있다면 CPU는 변위를 더해 10번지에 접근하게 된다. 프레임의 메모리 주소 + 변위 = 최종 메모리 주소가 된다.
5. 페이지 테이블 엔트리(PTE, Page Table Entry): 페이지 테이블의 각각의 행들
   1. 페이지 번호: 논리 주소
   2. 프레임 번호: 물리 주소
   3. 유효 비트: 현재 페이지에 접근 가능한지 알려준다. 프레임 번호 다음으로 중요한 정보이다. 페이지에 메모리에 있는지 스왑 영역에 있는지 알려준다. 메모리에 없는 유효 비트 0인 페이지에 접근하면 페이지 폴드page fault라는 예외가 발생한다. 발생하면 인터럽트 과정처럼 CPU가 기존 내용 백업하고 페이지 폴트 처리 루틴에 따라서 페이지 가져온 다음 유효 비트 1로 바꾸고 CPU는 이제 접근한다.
   4. 보호 피트: 페이지 보호 기능을 위해 존재하는 비트이다. 페이지가 읽거나(r) 쓰거나(w) 실행하는(x) 게 가능한지 나타내고 안 되는 행동을 하면 운영체제가 막는다.
   5. 참조 비트: CPU가 이 페이지에 접근한 적 있는지 여부를 나타낸다. 적재 이후 한번이라도 읽거나 쓴 페이지는 참조 비트가 1이 된다.
   6. 수정 비트: 해당 페이지에 데이터를 쓴 적이 있는지 없는지 수정 여부를 알려준다. 더티 비트라고도 부른다. 스왑 아웃시에 수정 비트가 0이라면 그냥 새 걸로 덮어쓰면 되지만, 변경값이 있다면 보조기억장치에도 동기화해놓아야 하기 때문에 필요하다.
### 14-3. 페이지 교체와 프레임 할당
1. 요구 페이징(demand paging): 처음부터 모든 페이지를 적재하지 않고 필요한 페이지만을 메모리에 적재하는 기법이다. CPU가 메모리 접근 시에 유효 비트가 1이면 접근하고 0이면 페이지 폴트 루틴대로 처리한다. 처음부터 아무것도 적재하지 않은 채로 시작하는 건 순수 요구 페이징pure demand paging이다. 요구 페이징 시스템이 잘 작동하기 위해선 페이지 교체와 프레임 할당을 잘 해야 한다.
2. 페이지 교체 알고리즘: 스왑할 메모리를 결정하는 알고리즘이다. 페이지 폴트를 가장 적게 일으키는 알고리즘이 좋다. 메모리는 언젠가 차기 마련이기 때문에 교체가 일어난다.
   1. FIFO 페이지 교체 알고리즘: 적재된 순서대로 교체한다.
   2. 최적 페이지 교체 알고리즘: 앞으로의 사용 빈도가 가장 낮은 페이지를 교체한다. 다른 알고리즘에 비해 가장 페이지 폴트가 적어 이상적이지만 실제 구현은 힘들다. 성능 평가를 위한 기준으로 사용된다.
   3. LRU 페이지 교체 알고리즘: 가장 오랫동안 사용되지 않은 페이지를 교체하는 알고리즘이다. 최적 알고리즘은 힘들지만 유사하게 변형한 방식이다.
3. 스래싱과 프레임 할당
   1. 스래싱(thrashing): 빈번한 페이지 교체로 인해 CPU 이용률(성능)이 낮아지는 문제다. 교체 알고리즘 때문만이 아니라 프레임 수가 적어도 페이지 폴트가 자주 발생한다. 프로세스 실행보다 페이지 교체에 더 많은 시간을 쓸 수 있다. 멀티 프로세스는 기본적으로 성능이 좋아지지만 프로세스 수(멀티프로그래밍 정도)가 과도하게 많아질 경우 각 프로세스마다 최소한의 프레임 수가 보장되지 않아 페이지 폴트가 빈번하게 발생해 성능이 떨어진다. 이를 위해 프로세스에 적절한 수의 프레임 할당을 해주는 게 중요하다
   2. 프레임 할당 방식
      1. 균등 할당: 모든 프로세스에 동일한 프레임을 배분한다.
      2. 비례 할당: 프로세스 크기에 따라 프레임을 배분한다.
      3. 작업 집합 모델: 프로세스가 과거에 일정 시간 동안 참조하던 페이지의 집합, 작업 집합working set의 크기만큼 프레임을 할당하는 방법이다. 프로세스는 참조 지역성 원리에 따라 주로 몇몇 개의 페이지 주소들만 집중적으로 참조하기 때문이다.
      4. 페이지 폴트 빈도: 페이지 폴트율의 상한선과 하한선을 정하고 상한선을 넘으면 프레임 수를 늘리고, 하한선보다 낮으면 프레임 수를 높여서 적정 프레임 수와 폴트율을 유지하는 방법이다.

## 15. 파일 시스템
### 15-1. 파일과 디렉터리
1. 파일: 보조기억장치에 저장된 관련 정보들의 집합을 의미한다. 정보들을 모은 논리적 단위이다. 파일은 이름과 실행을 위한 정보, 속성(메타데이터)로 구성된다. 속성에는 유형(.exe, .doc), 크기, 보호, 생성날짜, 생성자, 소유자 등이 있다. 파일을 다루려면 운영체제의 도움이 팔요하다. 파일 연산을 위해서는 파일 생성/삭제, 파일 열기/닫기, 파일 읽기/쓰기 등의 시스템 콜을 해야한다.
2. 디렉터리: 파일들을 일목 요연하게 관리하기 위한 파일이다. 파일에는 파일 관련 정보가 있다면, 디렉터리에는 담겨있는 파일 관련 정보들이 들어있다. 테이블(표)의 형태로 구성되어 이름, 위치를 유추할 수 있는 정보, 생성 시간 크기 등이 들어있다. 윈도우 운영체제에서는 폴더라고 부른다. 옛날 운영체제에서는 하나의 디렉토리만 있었다. 현재는 트리 구조 디렉터리를 사용한다. 계층 구조는 슬래시(/)를 사용해 표현한다. 그래서 생긴 개념이 path이다. 절대 경로는 루트부터, 상대 경로는 현재 디렉터리부터 시작한다. 당연히 디렉터리 연산을 위해서도 운영체제가 시스템 콜을 제공한다.
### 15-2. 파일 시스템
1. 파티셔닝: 큰 하나의 저장 장치를 여러 개의 논리적인 영역으로 구획하는 작업이다. 새 SSD를 산다면 바로 이 보조기억장치에 파일을 저장할 수 없고 파이셔닝과 포매핑을 해야 저장할 수 한다. 보조기억장치를 논리적 단위로 나눈다. 파티션 정보는 쉽게 확인할 수 있다.
2. 포매팅: 파일 시스템을 설정하는 작업이다. 어떤 방식으로 파일을 저장하고 관리할 것인지 결정된다. 파티션마다 다른 파일 시스템을 쓸 수 있다. 파일 시스템이 있어야 파일과 디렉터리를 만들고 사용할 수 있다.
3. 파일 할당 방법: 운영체제는 파일과 디렉터리를 블록 단위로 읽고 쓴다. 하드 디스크의 가장 작은 단위는 섹터지만 운영 체제는 섹터들을 블록 단위로 묶어서 관리한다.
   1. 연속 할당contiguous allocation: 가장 단순한 연속적으로 할당하는 방식이다. 파일 시스템은 파일 이름, 첫번쨰 블록 주소, 길이를 명시한다. 메모리 연속 할당과 같이 외부 단편화의 문제가 발생한다.
   2. 연결 할당linked allocation: 각 블록에 다음 블록에 주소를 저장해서 연결 리스트 형태로 관리하는 방식이다. 불연속적으로 할당되어도 무방하다. 파일 시스템은 마찬가지로 파일 이름, 첫번쨰 블록 주소, 길이를 명시한다. 외부 단편화는 해결할 수 있지만 순차 접근해야하기 때문에 특정 파일에 임의 접근random access 하는 것이 느리다. 또한 중간에 블록이 오류가 나면 이후 블록은 모두 접근할 수 없다. 그래서 오늘날에는 조금 변형해서 FAT 파일 시스템으로 이용한다.
   3. 색인 할당indexed allocation: 모든 블록 주소를 색인 블록index block이라는 하나의 블록에 모아 관리하는 방식이다. 파일 시스템은 파일 이름, 색인 블록 주소를 명시한다. 예를 들어 파일 a의 색인 블록이 4번이고 데이터가 든 블록은 7, 13, 11번이라면 4번 색인 블록에 7, 13, 11 주소가 저장되어 있다. i번째 블록에 바로 접근 하는 것도 가능하다.
3. 파일 시스템 살펴보기
   1. FAT 파일 시스템: FAT를 이용하는 연결 할당 기반의 파일 시스템이다. 각 블록에 포함된 다음 블록의 주소들을 테이블로 모아 놓은 파일 할당 테일 FAT(File Allocation Table)로 관리해서 연결 할당의 단점을 개선한다. USB 메모리, SD 같은 저용량 저장 장치용 파일 시스템으로 많이 쓰인다. FAT는 메모리에 캐시되어 더 빨리 접근될 수도 있다. 디렉터리 엔트리엔 파일 이름과 첫 번째 블록 주소가 명시된다. 파티션을 FAT 파일 시스템으로 포맷해보면 FAT 영역이 앞부분에 만들어지고, 그 다음 루트 디렉터리가 오고, 그다음 서브 디렉터리와 파일들을 위한 데이터 영역이 나온다. 경로가 주어지고 파일을 읽는다면, 경로에 따라서 디렉터리에 들어가고, 파일에 도착하면 FAT를 참조해서 파일 내용을 하나씩 읽는다.
   2. 유닉스 파일 시스템: i-node를 이용하는 색인 할당 기반 파일 시스템이다. 유닉스 파일 시스템에서는 색인 블록은 i-node라고 부른다. i-node에는 파일 속성 정보와 열다섯 개의 블록 주소가 저장될 수 있다. 파일마다 i-node가 있고 i-node마다 번호가 부여되어 있다. 디렉터리 엔트리엔 파일 이름과 i-node 번호가 명시되어있다. i-node는 FAT처럼 파티션 앞부분의 i-node 영역에 모여있다. 그 뒤에 데이터 영역이 있다. i-node가 나타낼 수 있는 주소는 한정적이기 때문에 직접 주소와 간접 주소를 혼용한다. 열두 개에는 파일 데이터가 저장된 직접 블록의 주소를 저장한다. 열세 번째에는 데이터 파일의 주소들이 저장된 단일 간접 블록의 주소를, 열네 번째에는 단일 간접 블록들의 주소가 저장된 이중 간접 블록의 주소를 저장한다. 그래도 모자라면 열다섯 번째엔 삼중 간접 블록을 저장한다. 경로가 주어지고 파일을 읽는다면, 먼저 유닉스 파일 시스템은 루트 디렉토리의 i-node를 항상 기억하기 때문에 i-node 영역으로 가서 해당 i-node 번호에 적힌 루트 디렉터리의 메모리 주소를 찾는다. 엔트리에 i-node 번호가 있기 때문에 서브 디렉토리로 가려면 해당 디렉토리의 이름과 i-node 번호를 찾고, 그 번호로 다시 i-node 영역에 가서 해당 i-node에 저장된 메모리 주소로 들어간다. 파일을 찾으면 해당 i-node에는 여러 개의 블록 주소가 저장되어 있다. 유닉스 파일 시스템은 디렉터리와 파일 검색에 모두 i-node를 사용한다.
   3. 그 외: 윈도우에서 쓰이는 NT 파일 시스템, 리눅스에서 운영되는 ext 파일 시스템 등이 있다.
4. 저널링 파일 시스템: 시스템 크래시 상황에서 저널링 기법을 통해 훼손된 파일 시스템을 빠르게 복구하는 시스템이다. 저널링은 작업 직전에 로그 영역에 로그를 남기고 작업이 끝나면 로그를 삭제하는 방식이다. 크래시가 발생하면 로그 영역의 로그만 검사하면 된다. 현대 대부분의 파일 시스템을 저널링을 지원한다.
5. 마운트: 저장 장치를 마운트한다는 것은 한 저장 장치의 파일 시스템에서 다른 저장 장치의 파일 시스템에 접근할 수 있도록 파일 시스템을 편입시키는 작업을 말한다. 예를 들어 USB 메모리의 파일 시스템을 컴퓨터의 /mnt 경로에 마운트하면 /mnt 경로에 USB의 파일 시스템이 연결되어 접근할 수 잇게 된다.
